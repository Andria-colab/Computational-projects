{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ffc1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "OUTPUT_FOLDER = \"tracking_results\"\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "# PART 1: MATH & PLOTTING\n",
    "\n",
    "def euclidean_distance(p1, p2):\n",
    "    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "\n",
    "def from_scratch_derivatives(position_track, fps):\n",
    "    if len(position_track) < 5:\n",
    "        return (np.array([]), np.array([]), np.array([]), np.array([]))\n",
    "        \n",
    "    dt = 1.0 / fps\n",
    "    positions = np.array(position_track)\n",
    "    \n",
    "    velocity = np.diff(positions, axis=0) / dt\n",
    "    speed = np.linalg.norm(velocity, axis=1)\n",
    "    \n",
    "    acceleration_vec = np.diff(velocity, axis=0) / dt\n",
    "    acceleration = np.linalg.norm(acceleration_vec, axis=1)\n",
    "    \n",
    "    jerk_vec = np.diff(acceleration_vec, axis=0) / dt\n",
    "    jerk = np.linalg.norm(jerk_vec, axis=1)\n",
    "    \n",
    "    jounce_vec = np.diff(jerk_vec, axis=0) / dt\n",
    "    jounce = np.linalg.norm(jounce_vec, axis=1)\n",
    "    \n",
    "    return speed, acceleration, jerk, jounce\n",
    "\n",
    "def save_derivative_plot(track_id, speed, acceleration, jerk, jounce, fps):\n",
    "    if speed.size == 0: return\n",
    "    \n",
    "    time_speed = np.arange(len(speed)) / fps\n",
    "    time_acc = np.arange(len(acceleration)) / fps\n",
    "    time_jerk = np.arange(len(jerk)) / fps\n",
    "    time_jounce = np.arange(len(jounce)) / fps\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle(f'Motion Derivatives for Track ID: {track_id}', fontsize=16)\n",
    "    \n",
    "    ax1.plot(time_speed, speed, 'b-', label='Speed')\n",
    "    ax1.set_title('Speed')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.plot(time_acc, acceleration, 'r-', label='Acceleration')\n",
    "    ax2.set_title('Acceleration')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax3.plot(time_jerk, jerk, 'g-', label='Jerk')\n",
    "    ax3.set_title('Jerk')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax4.plot(time_jounce, jounce, 'm-', label='Jounce')\n",
    "    ax4.set_title('Jounce')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = f\"{OUTPUT_FOLDER}/track_{track_id}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved graph for Track {track_id} to {filename}\")\n",
    "\n",
    "# PART 2: SIMPLE DBSCAN + ROBUST TRACKER\n",
    "\n",
    "def dbscan_numpy(points, eps=10, min_samples=3):\n",
    "    \"\"\"Simple DBSCAN with RELAXED parameters for better detection\"\"\"\n",
    "    if points.size == 0:\n",
    "        return np.array([], dtype=int)\n",
    "    \n",
    "    N = points.shape[0]\n",
    "    labels = -1 * np.ones(N, dtype=int)\n",
    "    visited = np.zeros(N, dtype=bool)\n",
    "    cluster_id = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        if visited[i]:\n",
    "            continue\n",
    "        visited[i] = True\n",
    "\n",
    "        diffs = points - points[i]\n",
    "        dists2 = np.einsum('ij,ij->i', diffs, diffs)\n",
    "        neighbors = np.where(dists2 <= eps * eps)[0]\n",
    "\n",
    "        if neighbors.size < min_samples:\n",
    "            labels[i] = -1\n",
    "        else:\n",
    "            labels[i] = cluster_id\n",
    "            seeds = list(neighbors[neighbors != i].tolist())\n",
    "            while seeds:\n",
    "                current = seeds.pop()\n",
    "                if not visited[current]:\n",
    "                    visited[current] = True\n",
    "                    diffs_c = points - points[current]\n",
    "                    dists2_c = np.einsum('ij,ij->i', diffs_c, diffs_c)\n",
    "                    nbrs_c = np.where(dists2_c <= eps * eps)[0]\n",
    "                    if nbrs_c.size >= min_samples:\n",
    "                        for n in nbrs_c:\n",
    "                            if n not in seeds:\n",
    "                                seeds.append(n)\n",
    "                if labels[current] == -1:\n",
    "                    labels[current] = cluster_id\n",
    "            cluster_id += 1\n",
    "    return labels\n",
    "\n",
    "class RobustTracker:\n",
    "    def __init__(self, blur_ksize, threshold_val, min_contour_area, max_track_distance, patience, dbscan_eps=10, dbscan_minpts=3, dbscan_sample_limit=5000):\n",
    "        self.blur_ksize = blur_ksize\n",
    "        self.threshold_val = threshold_val\n",
    "        self.min_contour_area = min_contour_area\n",
    "        self.max_track_distance = max_track_distance\n",
    "        self.patience_limit = patience\n",
    "        \n",
    "        self.prev_frame_gray = None\n",
    "        self.tracks = {} \n",
    "        self.track_patience = {} \n",
    "        self.next_track_id = 0\n",
    "        self.frame_number = 0\n",
    "\n",
    "        # RELAXED DBSCAN params\n",
    "        self.dbscan_eps = dbscan_eps\n",
    "        self.dbscan_minpts = dbscan_minpts\n",
    "        self.dbscan_sample_limit = dbscan_sample_limit\n",
    "\n",
    "    def _preprocess_frame(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, self.blur_ksize, 0)\n",
    "        return blurred\n",
    "\n",
    "    def _update_tracks(self, current_centroids):\n",
    "        self.frame_number += 1\n",
    "        \n",
    "        if not self.tracks:\n",
    "            for centroid in current_centroids:\n",
    "                self.tracks[self.next_track_id] = [centroid]\n",
    "                self.track_patience[self.next_track_id] = self.patience_limit\n",
    "                self.next_track_id += 1\n",
    "            return\n",
    "\n",
    "        active_track_ids = list(self.tracks.keys())\n",
    "        last_positions = [self.tracks[tid][-1] for tid in active_track_ids]\n",
    "        \n",
    "        matched_new_centroids = set()\n",
    "        matched_track_ids = set()\n",
    "\n",
    "        for idx, track_id in enumerate(active_track_ids):\n",
    "            last_pos = last_positions[idx]\n",
    "            \n",
    "            best_dist = float('inf')\n",
    "            best_centroid_idx = -1\n",
    "            \n",
    "            for i, centroid in enumerate(current_centroids):\n",
    "                if i in matched_new_centroids:\n",
    "                    continue\n",
    "                \n",
    "                dist = euclidean_distance(last_pos, centroid)\n",
    "                if dist < best_dist:\n",
    "                    best_dist = dist\n",
    "                    best_centroid_idx = i\n",
    "            \n",
    "            if best_dist < self.max_track_distance and best_centroid_idx != -1:\n",
    "                self.tracks[track_id].append(current_centroids[best_centroid_idx])\n",
    "                self.track_patience[track_id] = self.patience_limit\n",
    "                \n",
    "                matched_new_centroids.add(best_centroid_idx)\n",
    "                matched_track_ids.add(track_id)\n",
    "        \n",
    "        for track_id in active_track_ids:\n",
    "            if track_id not in matched_track_ids:\n",
    "                if track_id not in self.track_patience:\n",
    "                     self.track_patience[track_id] = 0\n",
    "                self.track_patience[track_id] -= 1\n",
    "\n",
    "        for i, centroid in enumerate(current_centroids):\n",
    "            if i not in matched_new_centroids:\n",
    "                self.tracks[self.next_track_id] = [centroid]\n",
    "                self.track_patience[self.next_track_id] = self.patience_limit\n",
    "                self.next_track_id += 1\n",
    "\n",
    "    def _draw_overlay(self, frame, num_objects, processing_time):\n",
    "        cv2.putText(frame, f\"Objects: {num_objects}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        for track_id, positions in self.tracks.items():\n",
    "            if self.track_patience.get(track_id, 0) > 0:\n",
    "                last_pos = positions[-1]\n",
    "                cv2.circle(frame, last_pos, 6, (0, 0, 255), -1)\n",
    "                cv2.putText(frame, f\"ID:{track_id}\", (last_pos[0]+10, last_pos[1]), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        return frame\n",
    "\n",
    "    def _detect_objects_via_dbscan(self, motion_mask):\n",
    "        \"\"\"Detect objects using DBSCAN clustering\"\"\"\n",
    "        ys, xs = np.where(motion_mask > 0)\n",
    "        if xs.size == 0:\n",
    "            return []\n",
    "\n",
    "        points = np.column_stack((xs, ys)).astype(np.float32)\n",
    "        N = points.shape[0]\n",
    "        \n",
    "        # Sample if too many points\n",
    "        if N > self.dbscan_sample_limit:\n",
    "            idxs = np.random.choice(N, self.dbscan_sample_limit, replace=False)\n",
    "            points_sampled = points[idxs]\n",
    "            sampled_map = idxs\n",
    "        else:\n",
    "            points_sampled = points\n",
    "            sampled_map = None\n",
    "\n",
    "        labels_sampled = dbscan_numpy(points_sampled, eps=self.dbscan_eps, min_samples=self.dbscan_minpts)\n",
    "        unique_labels = np.unique(labels_sampled)\n",
    "        centroids = []\n",
    "\n",
    "        for lbl in unique_labels:\n",
    "            if lbl == -1:\n",
    "                continue\n",
    "            mask = labels_sampled == lbl\n",
    "            cluster_points = points_sampled[mask]\n",
    "\n",
    "            if sampled_map is not None:\n",
    "                est_centroid = cluster_points.mean(axis=0)\n",
    "                diffs_full = points - est_centroid\n",
    "                d2_full = np.einsum('ij,ij->i', diffs_full, diffs_full)\n",
    "                cluster_full_idx = np.where(d2_full <= (self.dbscan_eps * 1.5)**2)[0]\n",
    "                area = cluster_full_idx.size\n",
    "                if area < self.min_contour_area:\n",
    "                    continue\n",
    "                centroid = tuple(np.round(est_centroid).astype(int).tolist())\n",
    "                centroids.append(centroid)\n",
    "            else:\n",
    "                area = cluster_points.shape[0]\n",
    "                if area < self.min_contour_area:\n",
    "                    continue\n",
    "                centroid = tuple(np.round(cluster_points.mean(axis=0)).astype(int).tolist())\n",
    "                centroids.append(centroid)\n",
    "\n",
    "        return centroids\n",
    "\n",
    "    def process_video(self, video_path, output_video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error opening video\")\n",
    "            return None, 0\n",
    "        \n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        # initialize previous frame BEFORE loop\n",
    "        ret, first_frame = cap.read()\n",
    "        if not ret: \n",
    "            print(\"Cannot read first frame\")\n",
    "            return None, 0\n",
    "        \n",
    "        self.prev_frame_gray = self._preprocess_frame(first_frame)\n",
    "        print(f\"Video loaded: {width}x{height} @ {fps} fps\")\n",
    "        \n",
    "        frame_count = 0\n",
    "        while cap.isOpened():\n",
    "            start_time = time.time()\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: \n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Preprocess\n",
    "            current_frame_gray = self._preprocess_frame(frame)\n",
    "            \n",
    "            # Motion detection\n",
    "            diff_frame = cv2.absdiff(current_frame_gray, self.prev_frame_gray)\n",
    "            _, motion_mask = cv2.threshold(diff_frame, self.threshold_val, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # IMPROVED: Opening + Dilation\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "            motion_mask = cv2.dilate(motion_mask, kernel, iterations=2)\n",
    "            \n",
    "            # Detect objects\n",
    "            current_centroids = self._detect_objects_via_dbscan(motion_mask)\n",
    "            \n",
    "            # Update tracks\n",
    "            self._update_tracks(current_centroids)\n",
    "            \n",
    "            proc_ms = (time.time() - start_time) * 1000\n",
    "            \n",
    "            # Display\n",
    "            display_frame = self._draw_overlay(frame, len(current_centroids), proc_ms)\n",
    "            writer.write(display_frame)\n",
    "            cv2.imshow(\"Robust Tracking (DBSCAN)\", display_frame)\n",
    "            \n",
    "            self.prev_frame_gray = current_frame_gray\n",
    "            \n",
    "            if frame_count % 30 == 0:\n",
    "                print(f\"Processed {frame_count} frames, detected {len(current_centroids)} objects\")\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        writer.release()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "        print(f\"\\nTotal frames processed: {frame_count}\")\n",
    "        print(f\"Total tracks created: {self.next_track_id}\")\n",
    "        \n",
    "        return self.tracks, fps\n",
    "\n",
    "    def analyze_tracks_wrapper(self, fps):\n",
    "        print(\"\\n--- Post-Processing Analysis ---\")\n",
    "        count = 0\n",
    "        for track_id, positions in self.tracks.items():\n",
    "            if len(positions) < 30: \n",
    "                continue\n",
    "            \n",
    "            s, a, j, s4 = from_scratch_derivatives(positions, fps)\n",
    "            save_derivative_plot(track_id, s, a, j, s4, fps)\n",
    "            count += 1\n",
    "        \n",
    "        if count == 0:\n",
    "            print(\"No long tracks found. Try adjusting parameters.\")\n",
    "        else:\n",
    "            print(f\"Analyzed {count} tracks\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # RELAXED PARAMETERS for better detection\n",
    "    tracker = RobustTracker(\n",
    "        blur_ksize=(15, 15),\n",
    "        threshold_val=20,           # LOWERED from 25\n",
    "        min_contour_area=50,        # LOWERED from 200\n",
    "        max_track_distance=150,\n",
    "        patience=15,\n",
    "        dbscan_eps=10,              # INCREASED from 4\n",
    "        dbscan_minpts=3,            # LOWERED from 8\n",
    "        dbscan_sample_limit=5000\n",
    "    )\n",
    "    \n",
    "    tracks, video_fps = tracker.process_video('output.mp4', 'processed_video.mp4')\n",
    "    \n",
    "    if tracks:\n",
    "        tracker.analyze_tracks_wrapper(video_fps)\n",
    "    else:\n",
    "        print(\"No tracks found. Check your video file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
